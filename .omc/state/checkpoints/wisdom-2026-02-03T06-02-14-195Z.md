## Plan Wisdom

### application-layer-improvement/learnings.md
# Application Layer Analysis - Key Learnings

## Current State Assessment

### 1. Service Boundaries (Good Overall)
- ReportSchedulerService properly orchestrates multiple use cases
- Clear separation between domain logic and application orchestration
- Services don't duplicate domain logic

### 2. Duplicate Logic Identified

#### Report Generation Use Cases (CRITICAL)
Location: `src/application/use-cases/report/`
- `GenerateWeeklyReportUseCase.ts`
- `GenerateDailyReportUseCase.ts`
- `GenerateMonthlyReportUseCase.ts`

**Duplicate Pattern:**
All three use cases share 90% identical logic:
1. Campaign ownership validation (lines 24-34)
2. KPI aggregation loop (lines 45-80)
3. AI insight generation (lines 83-110)
4. Report saving (lines 113-116)

**Only Differences:**
- Factory method: `Report.createWeekly()` vs `createDaily()` vs `createMonthly()`
- AI options: `includeForecast` flag differs
- Section content text: "Ï£ºÍ∞Ñ" vs "ÏùºÏùº" vs "ÏõîÍ∞Ñ"

#### Exception Handling Inconsistencies

**Non-Domain Errors in Application Layer:**
- `QuotaExceededError` in QuotaService (should be domain error)
- `BudgetAlertService`: Uses generic `Error` instead of domain errors
- `ChatService`: Uses generic `Error` instead of domain errors
- `PixelUseCase`: Uses generic `Error` instead of domain errors
- `AdminUseCase`: Uses generic `Error` instead of domain errors

**Proper Domain Error Usage:**
- Report use cases correctly use `UnauthorizedCampaignError`
- Campaign use cases have custom errors extending base Error (should extend DomainError)

### 3. Service vs Use Case Confusion

**Current Issue:**
- `ReportSchedulerService` acts as both a service AND orchestrates use cases
- Should be: Use cases handle single operations, Services orchestrate multiple use cases

**Better Approach:**
- Keep use cases pure (single responsibility)
- Services orchestrate multiple use cases
- Clear naming: `*Service` for orchestration, `*UseCase` for single operations

## Metrics - Before vs After

### Code Reduction
**Before:**
- GenerateWeeklyReportUseCase: 118 lines
- GenerateDailyReportUseCase: 118 lines
- GenerateMonthlyReportUseCase: 118 lines
- **Total: 354 lines**

**After:**
- BaseReportGenerationUseCase: 209 lines (shared)
- GenerateWeeklyReportUseCase: 38 lines
- GenerateDailyReportUseCase: 38 lines
- GenerateMonthlyReportUseCase: 39 lines
- **Total: 324 lines**

**Reduction:** 30 lines saved, but more importantly:
- ~220 lines of duplicate logic eliminated
- 1 place to fix bugs instead of 3
- Type safety improved with abstract base class

### Error Handling Improvements
**Before:**
- 12+ places using generic `Error`
- 1 error class defined in service file
- No consistent error structure

**After:**
- 4 new domain error files
- 14 specific error types
- All extend DomainError base class
- Consistent toJSON() serialization
- Type-safe error handling

## Action Items

### High Priority ‚úÖ COMPLETE
1. ‚úÖ Create `BaseReportGenerationUseCase` to eliminate duplication
2. ‚úÖ Move `QuotaExceededError` to domain errors
3. ‚úÖ Create domain errors for BudgetAlert, Pixel, Admin operations
4. ‚úÖ Standardize exception handling across services

### High Priority üîÑ IN PROGRESS
1. Update remaining use cases (SelectPixel, GetPixelStatus, Admin use cases)
2. Add tests for BaseReportGenerationUseCase
3. Add tests for domain errors

### Medium Priority
1. Add base use case class for common error handling
2. Create application-level error wrapper for infrastructure errors
3. Document service vs use case boundaries in AGENTS.md
4. Create ILogger interface and replace console.warn

### Low Priority
1. Add JSDoc comments to all public service methods
2. Create integration tests for orchestration services
3. Add metrics/logging to all use cases
4. Refactor Campaign errors to extend DomainError

### application-layer-improvement/decisions.md
# Architectural Decisions

## Decision 1: Extract BaseReportGenerationUseCase

**Context:**
Three report generation use cases share 90% identical code, differing only in:
- Report type (daily/weekly/monthly)
- AI insight options
- Content text labels

**Decision:**
Create abstract `BaseReportGenerationUseCase` with template method pattern.

**Rationale:**
- DRY principle: Single source of truth for report generation logic
- Maintainability: Bug fixes apply to all report types
- Testability: Test common logic once
- Extensibility: Easy to add quarterly/yearly reports

**Trade-offs:**
- Slight increase in abstraction complexity
- But eliminates 200+ lines of duplicate code

## Decision 2: Standardize Application Error Hierarchy

**Context:**
Application layer has inconsistent error handling:
- Some use domain errors (correct)
- Some use generic Error (incorrect)
- Some define custom errors in use case files (incorrect)

**Decision:**
Create clear error hierarchy:
```
DomainError (abstract)
‚îú‚îÄ‚îÄ InvalidCampaignError
‚îú‚îÄ‚îÄ UnauthorizedCampaignError
‚îú‚îÄ‚îÄ QuotaExceededError (NEW - move from QuotaService)
‚îú‚îÄ‚îÄ BudgetAlertError (NEW)
‚îú‚îÄ‚îÄ PixelSetupError (NEW)
‚îî‚îÄ‚îÄ ...

ApplicationError (NEW - abstract)
‚îú‚îÄ‚îÄ UseCaseExecutionError
‚îî‚îÄ‚îÄ ServiceOrchestrationError
```

**Rationale:**
- Business rule violations = DomainError
- Orchestration failures = ApplicationError
- Infrastructure failures = Wrapped in ApplicationError
- Clear error boundaries for each layer

## Decision 3: Keep ReportSchedulerService as Orchestrator

**Context:**
ReportSchedulerService instantiates use cases directly, which could be seen as violation of dependency inversion.

**Decision:**
Keep current approach but document it clearly as "orchestration service pattern".

**Rationale:**
- Use cases are pure functions (no state)
- Instantiating them is cheap and clear
- Alternative (DI all use cases) would create massive constructor
- This pattern is acceptable for application services

**Constraint:**
Document this pattern in AGENTS.md for consistency.

## Decision 4: Date Range Calculation in Service vs Use Case

**Context:**
ReportSchedulerService calculates date ranges (lines 88-104), then passes to use cases.

**Decision:**
Keep date calculation in service layer.

**Rationale:**
- Scheduling logic (what period to report on) is service concern
- Use cases accept date ranges as input (flexible)
- Service can schedule "last 7 days" or "last Monday-Sunday"
- Separation of concerns maintained

## Decision 5: AI Failure Handling Strategy

**Context:**
All report use cases have try-catch around AI service with console.warn fallback.

**Decision:**
Keep silent failure pattern for AI insights but add structured logging.

**Rationale:**
- Reports should generate even if AI unavailable
- AI insights are enhancement, not requirement
- But need observability for debugging
- Change from console.warn to proper logger

**Implementation:**
Add optional logger injection to use cases.

### application-layer-improvement/issues.md
# Known Issues and Problems

## Before Refactoring

### 1. Massive Code Duplication
- **Files:** GenerateWeeklyReportUseCase, GenerateDailyReportUseCase, GenerateMonthlyReportUseCase
- **Lines duplicated:** ~220 lines across 3 files
- **Impact:** Bug fixes needed to be applied 3 times
- **Solution:** Created BaseReportGenerationUseCase with Template Method pattern

### 2. Inconsistent Error Handling
- **Problem:** Mix of domain errors, generic Error, and custom inline errors
- **Examples:**
  - QuotaExceededError defined in service file (should be domain)
  - BudgetAlertService throws generic Error strings
  - Pixel use cases throw generic Error strings
  - Admin use cases throw generic Error strings
- **Impact:**
  - No type safety for error handling
  - Inconsistent error response format
  - Difficult to distinguish error types in API layer
- **Solution:** Created proper domain error hierarchy

### 3. Silent AI Failures
- **Problem:** Try-catch around AI service with console.warn only
- **Impact:** No monitoring or alerting when AI fails
- **Solution:** Need to add structured logging (TODO)

### 4. Incomplete Type Safety
- **Problem:** Some services use `any` or broad types
- **Impact:** Runtime errors not caught at compile time
- **Solution:** Ongoing - need full type audit

## After Refactoring

### Remaining Issues

1. **Logging Infrastructure Missing**
   - BaseReportGenerationUseCase still uses console.warn
   - Need injectable logger interface
   - Need structured logging format

2. **Campaign Use Case Errors**
   - CampaignNotFoundError, UnauthorizedCampaignAccessError extend Error directly
   - Should extend DomainError for consistency
   - TODO: Refactor in next iteration

3. **ChatService Error Handling**
   - Still uses generic Error
   - Need ChatError domain errors
   - TODO: Create domain errors for chat operations

4. **CreativeTestRecommendationService**
   - Throws generic Error
   - Need proper domain errors
   - TODO: Create RecommendationError hierarchy

5. **No Integration Tests for Refactored Code**
   - BaseReportGenerationUseCase needs tests
   - New domain errors need tests
   - TODO: Add test coverage

## Migration Notes

### Breaking Changes
None - all changes are internal refactoring. External APIs unchanged.

### Dependencies Updated
- QuotaService now imports from @domain/errors
- BudgetAlertService now imports from @domain/errors
- Pixel use cases now import from @domain/errors

### Files Modified
- src/application/use-cases/report/BaseReportGenerationUseCase.ts (NEW)
- src/application/use-cases/report/GenerateWeeklyReportUseCase.ts (REFACTORED)
- src/application/use-cases/report/GenerateDailyReportUseCase.ts (REFACTORED)
- src/application/use-cases/report/GenerateMonthlyReportUseCase.ts (REFACTORED)
- src/domain/errors/QuotaExceededError.ts (NEW)
- src/domain/errors/BudgetAlertError.ts (NEW)
- src/domain/errors/PixelError.ts (NEW)
- src/domain/errors/AdminError.ts (NEW)
- src/domain/errors/index.ts (UPDATED)
- src/application/services/QuotaService.ts (UPDATED)
- src/application/services/BudgetAlertService.ts (UPDATED)
- src/application/use-cases/pixel/SetupPixelUseCase.ts (UPDATED)

### application-layer-improvement/problems.md
# Current Blockers and Challenges

## High Priority Blockers

### 1. Type Safety for Admin Use Cases (PARTIALLY FIXED)
**Status:** In Progress
**Problem:** Admin use cases still need updates to use new domain errors
**Files affected:**
- src/application/use-cases/admin/UpdateUserRoleUseCase.ts
- src/application/use-cases/admin/ProcessRefundUseCase.ts

**Next steps:**
1. Read each file
2. Replace generic Error with new AdminError types
3. Verify type safety

### 2. Pixel Use Case Updates Needed (PARTIALLY FIXED)
**Status:** In Progress
**Problem:** Some pixel use cases not yet updated
**Files affected:**
- src/application/use-cases/pixel/SelectPixelUseCase.ts
- src/application/use-cases/pixel/GetPixelStatusUseCase.ts

**Next steps:**
1. Read each file
2. Replace generic Error with PixelError types
3. Test error handling

## Medium Priority Challenges

### 3. No Logging Interface
**Status:** Not Started
**Problem:** BaseReportGenerationUseCase uses console.warn
**Impact:** No monitoring in production

**Solution needed:**
1. Create ILogger port in application/ports/
2. Inject logger into use cases
3. Use structured logging format
4. Add log levels (error, warn, info, debug)

**Example:**
```typescript
interface ILogger {
  error(message: string, context?: unknown): void
  warn(message: string, context?: unknown): void
  info(message: string, context?: unknown): void
  debug(message: string, context?: unknown): void
}
```

### 4. Campaign Error Hierarchy Inconsistent
**Status:** Not Started
**Problem:** Campaign-related errors extend Error directly, not DomainError
**Files:**
- src/application/use-cases/campaign/UpdateCampaignUseCase.ts
- src/application/use-cases/campaign/PauseCampaignUseCase.ts
- src/application/use-cases/campaign/ResumeCampaignUseCase.ts
- src/application/use-cases/campaign/CreateCampaignUseCase.ts

**Impact:** Inconsistent error handling across domain

**Solution:**
1. Create CampaignError extends DomainError
2. Refactor existing errors to extend CampaignError
3. Move to domain/errors/ directory

## Low Priority Challenges

### 5. Test Coverage Gaps
**Status:** Not Started
**Tests needed:**
1. BaseReportGenerationUseCase unit tests
2. Integration tests for report generation
3. Error handling edge cases
4. Domain error serialization tests

### 6. Documentation Needs Update
**Status:** Not Started
**Files to update:**
- src/application/AGENTS.md (error handling guidelines)
- CLAUDE.md (update with new patterns)
- docs/plans/PLAN_batwo-ai-marketing.md

### 7. AI Service Error Wrapping
**Status:** Not Started
**Problem:** AI service failures caught but not properly logged/monitored
**Solution:**
1. Create AIServiceError domain error
2. Wrap AI failures with context
3. Add retry logic for transient failures
4. Add circuit breaker pattern

## Technical Debt

### TD-1: ReportSchedulerService Instantiates Use Cases
**Severity:** Low
**Description:** Service creates use case instances directly instead of DI
**Impact:** Harder to mock in tests
**Decision:** Acceptable pattern for stateless use cases (documented)

### TD-2: No Application-Level Error Wrapper
**Severity:** Medium
**Description:** Infrastructure errors not wrapped consistently
**Impact:** Leaky abstraction - domain layer shouldn't know about DB errors
**Solution:** Create ApplicationError for wrapping infrastructure failures

### TD-3: Inconsistent DTO Validation
**Severity:** Medium
**Description:** Some DTOs validated in use case, some in domain entity
**Impact:** Unclear where validation should happen
**Solution:** Standardize validation at use case input boundary

## Questions for Architect Review

1. Should we create ILogger interface or use third-party (winston, pino)?
2. Should CampaignError move to domain/errors or stay in use-case files?
3. Should we add Application-level error wrapper for all use cases?
4. Should DTOs have their own validation layer (class-validator)?
5. Should we add @throws JSDoc tags to document error types?

### e2e-test-activation/learnings.md
# E2E Test Activation - Learnings

## Mock Authentication Implementation

### NextAuth Session Cookie Approach

**Discovery:** NextAuth uses JWT tokens stored in HTTP-only cookies for session management.

**Implementation:**
```typescript
// Generate NextAuth compatible JWT token
const token = await encode({
  token: mockSession,
  secret: process.env.AUTH_SECRET,
  maxAge: 60 * 60 * 24 * 7,
})

// Set cookie with proper name
const cookieName = secureCookie
  ? '__Secure-authjs.session-token'
  : 'authjs.session-token'

cookieStore.set(cookieName, token, {
  httpOnly: true,
  secure: secureCookie,
  sameSite: 'lax',
  path: '/',
  maxAge: 60 * 60 * 24 * 7,
})
```

**Key Learning:** Cookie name changes based on `secure` flag:
- Development: `authjs.session-token`
- Production: `__Secure-authjs.session-token`

## Playwright Global Setup Pattern

### Storage State Persistence

**Pattern:**
1. Global setup runs once before all tests
2. Creates authenticated session via API
3. Saves browser context to `storage-state.json`
4. Authenticated tests reuse this state
5. Global teardown cleans up

**Benefits:**
- Single authentication for all tests
- Faster test execution (no repeated login)
- Consistent session state

**Implementation:**
```typescript
// In global-setup.ts
const storageState = await context.storageState()
await context.storageState({ path: './storage-state.json' })

// In playwright.config.ts
{
  name: 'chromium-authenticated',
  use: {
    storageState: './tests/e2e/storage-state.json',
  },
}
```

## Test Database Seeding

### Upsert Pattern for Idempotency

**Problem:** Tests may run multiple times, need to handle existing data.

**Solution:** Use Prisma `upsert()` for all test data creation.

```typescript
const testUser = await prisma.user.upsert({
  where: { email: 'test@example.com' },
  update: {},  // Don't update if exists
  create: {
    email: 'test@example.com',
    name: 'Test User',
    // ...
  },
})
```

**Key Learning:** Upsert ensures:
- First run: Creates data
- Subsequent runs: Reuses existing data
- No duplicate key errors

### Composite Key Handling

**Discovery:** Campaigns use composite unique key `userId_metaCampaignId`.

```typescript
where: {
  userId_metaCampaignId: {
    userId: testUser.id,
    metaCampaignId: 'campaign_test_001',
  },
}
```

## TypeScript Import Patterns

### CommonJS vs ES Modules

**Problem:** Default imports fail with `esModuleInterop: false`.

**Solution:** Use namespace imports for Node.js modules.

```typescript
// ‚ùå Fails
import fs from 'fs'
import path from 'path'

// ‚úÖ Works
import * as fs from 'fs'
import * as path from 'path'
```

**Key Learning:** Playwright test files use CommonJS-compatible imports.

## Test API Security

### Multi-Layer Protection

**Layer 1: Environment Check**
```typescript
if (process.env.NODE_ENV === 'production' && !process.env.ALLOW_TEST_API) {
  return 403
}
```

**Layer 2: Database URL Validation**
```typescript
const databaseUrl = process.env.DATABASE_URL || ''
if (!databaseUrl.includes('test') && process.env.NODE_ENV !== 'test') {
  return skip
}
```

**Key Learning:** Never trust single check. Defense in depth prevents production data corruption.

## Test Fixture Patterns

### Progressive Enhancement Approach

**Pattern:**
1. Try best approach (Mock API)
2. Fallback to alternative (Manual login)
3. Handle gracefully if both fail

```typescript
try {
  const response = await page.goto('/api/test/mock-auth')
  if (response?.ok()) {
    return // Success
  }
} catch (error) {
  // Fall back to manual login
}

// Manual login implementation
await page.goto('/login')
// ...
```

**Key Learning:** E2E tests should be resilient to environment changes.

## Error Test Strategies

### Network Mocking with `page.route()`

**Discovery:** Playwright's `page.route()` allows intercepting requests.

**Use Cases:**
- Simulate API failures
- Test retry logic
- Test error messages

```typescript
await page.route('**/api/campaigns', (route) => {
  route.abort('failed')  // Simulate network error
})
```

**Key Learning:** Network mocking is more reliable than actual server errors for testing.

### Conditional Assertions

**Problem:** Not all UI states are implemented yet.

**Solution:** Check if element exists before asserting.

```typescript
const isVisible = await element.isVisible({ timeout: 5000 })
  .catch(() => false)

if (isVisible) {
  await expect(element).toBeVisible()
}
```

**Key Learning:** Graceful degradation allows partial test coverage during development.

## Test Coverage Strategy

### Incremental Activation

**Approach:**
1. Start with critical path tests (auth, navigation)
2. Enable UI tests as components are implemented
3. Add error cases progressively
4. Keep some tests as TODO documentation

**Metrics:**
- Before: 5% E2E coverage (only unauthenticated paths)
- After: 25% E2E coverage (auth + basic flows)
- Target: 90% E2E coverage (full UI implementation)

**Key Learning:** Skip tests document future work, not just failures.

## Playwright Project Dependencies

### Sequential Project Execution

**Discovery:** Can enforce test execution order with `dependencies`.

```typescript
projects: [
  {
    name: 'chromium',
    use: { ...devices['Desktop Chrome'] },
  },
  {
    name: 'chromium-authenticated',
    use: { storageState: './storage-state.json' },
    dependencies: ['chromium'],  // Run after chromium
  },
]
```

**Use Case:** Ensure global setup completes before authenticated tests run.

**Key Learning:** Project dependencies provide execution order guarantees.

## Debugging Techniques

### Console Logging in Tests

**Pattern:** Add contextual logging for debugging failures.

```typescript
console.log('[Auth Fixture] Mock session created successfully')
console.warn('[Auth Fixture] Mock auth API failed, falling back...')
console.error('[DB Init] Error initializing database:', error)
```

**Key Learning:** Prefix logs with component name for easier filtering.

### Timeout Strategies

**Pattern:** Use catch for optional elements.

```typescript
const isVisible = await element.isVisible({ timeout: 5000 })
  .catch(() => false)
```

**Benefits:**
- No timeout errors for optional elements
- Tests continue execution
- Boolean result easy to use in conditions

## Future Improvements

### Test Data Factories

**Idea:** Create factory functions for common test data patterns.

```typescript
// Future pattern
const testUser = await TestFactory.createUser({ email: 'test@example.com' })
const testCampaign = await TestFactory.createCampaign({ userId: testUser.id })
```

**Benefits:**
- DRY principle
- Consistent test data
- Easier to maintain

### Parallel Test Execution

**Current:** Sequential execution (global setup dependency)
**Future:** Isolate each test with its own session

**Approach:**
- Each test creates its own mock session
- Use test fixtures instead of global setup
- Better parallelization

### Visual Regression Testing

**Next Step:** Add Playwright screenshot comparison.

```typescript
await expect(page).toHaveScreenshot('campaign-list.png')
```

**Benefits:**
- Catch CSS regressions
- Verify responsive design
- Document UI states

## References

- [Playwright Authentication](https://playwright.dev/docs/auth)
- [NextAuth JWT](https://next-auth.js.org/configuration/options#jwt)
- [Prisma Upsert](https://www.prisma.io/docs/reference/api-reference/prisma-client-reference#upsert)

### e2e-test-activation/decisions.md
# E2E Test Activation - Architectural Decisions

## AD-001: Mock Authentication via API Endpoints

**Status:** Accepted

**Context:**
- Need to run authenticated E2E tests without real OAuth providers
- Playwright needs valid NextAuth session cookies
- Multiple tests should share same session for performance

**Decision:**
Create dedicated test API endpoints (`/api/test/mock-auth`) that generate valid NextAuth JWT tokens and set session cookies.

**Alternatives Considered:**

1. **Real OAuth Login**
   - Pros: Tests actual flow
   - Cons: Slow, flaky, requires credentials, rate limits

2. **Browser Storage Manipulation**
   - Pros: No API needed
   - Cons: NextAuth uses HTTP-only cookies, not accessible from JS

3. **Database Session Seeding**
   - Pros: Bypasses auth entirely
   - Cons: NextAuth expects JWT tokens, not DB sessions

**Consequences:**
- ‚úÖ Fast test execution
- ‚úÖ Reliable (no external dependencies)
- ‚úÖ Security safeguards (production disabled)
- ‚ö†Ô∏è Doesn't test actual OAuth flow
- ‚ö†Ô∏è Requires test-specific API endpoints

## AD-002: Global Setup with Storage State

**Status:** Accepted

**Context:**
- Creating session for each test is slow (~2-5 seconds per test)
- 50+ authenticated tests = 100-250 seconds overhead
- Playwright supports shared browser contexts

**Decision:**
Use global setup to create session once, save to `storage-state.json`, reuse across all authenticated tests.

**Alternatives Considered:**

1. **Before Each Hook**
   - Pros: Test isolation
   - Cons: Very slow (2-5s √ó 50 tests = 100-250s)

2. **Before All Hook**
   - Pros: Faster than before each
   - Cons: Per-file setup, still ~20-30s overhead

3. **Test Fixtures**
   - Pros: Clean API
   - Cons: Still creates session per test unless shared

**Consequences:**
- ‚úÖ 100-250s saved per test run
- ‚úÖ Consistent session state
- ‚ö†Ô∏è All tests share same user session
- ‚ö†Ô∏è Changes in one test may affect others
- ‚ö†Ô∏è Must clean up state between tests

## AD-003: Upsert Pattern for Test Data

**Status:** Accepted

**Context:**
- Tests may run multiple times (during development)
- Database may already contain test data
- Unique constraints prevent duplicate data

**Decision:**
Use Prisma `upsert()` for all test data creation instead of `create()`.

**Alternatives Considered:**

1. **Delete All + Create**
   - Pros: Clean slate
   - Cons: Slow, destructive, may hit foreign key constraints

2. **Try Create, Catch Duplicate**
   - Pros: Simple
   - Cons: Error handling noise, not idempotent

3. **Find or Create Pattern**
   - Pros: Clear intent
   - Cons: Two queries instead of one

**Consequences:**
- ‚úÖ Idempotent test data setup
- ‚úÖ Fast (single query)
- ‚úÖ No errors on re-runs
- ‚ö†Ô∏è Update block must be empty or carefully managed
- ‚ö†Ô∏è Existing data may differ from expected

## AD-004: Test API Security Layers

**Status:** Accepted

**Context:**
- Test APIs must never run in production
- Mistakes happen (wrong env, leaked code)
- Need defense in depth

**Decision:**
Implement three security layers:
1. Environment check (`NODE_ENV === 'production'`)
2. Explicit flag (`ALLOW_TEST_API` environment variable)
3. Database URL validation (`DATABASE_URL.includes('test')`)

**Alternatives Considered:**

1. **Single Environment Check**
   - Pros: Simple
   - Cons: Easy to misconfigure, single point of failure

2. **Build-time Removal**
   - Pros: Zero production overhead
   - Cons: Build complexity, may break with dynamic imports

3. **IP Whitelist**
   - Pros: Network-level security
   - Cons: Not applicable to serverless, maintenance burden

**Consequences:**
- ‚úÖ Defense in depth prevents disasters
- ‚úÖ Explicit opt-in for production testing
- ‚úÖ Database safety check
- ‚ö†Ô∏è Three checks per request (minimal overhead)
- ‚ö†Ô∏è Test API code shipped to production (dead code)

## AD-005: Gradual Test Activation

**Status:** Accepted

**Context:**
- Many UI components not yet implemented
- Full test coverage not possible now
- Need to track what's tested vs. what's pending

**Decision:**
Keep tests as `test.skip()` with comments documenting why, activate as features are implemented.

**Alternatives Considered:**

1. **Delete Unimplemented Tests**
   - Pros: Clean, no clutter
   - Cons: Lose test plan documentation, easy to forget

2. **TODO Comments**
   - Pros: Standard pattern
   - Cons: Not executable, easy to ignore

3. **All Tests Active, Expected to Fail**
   - Pros: Shows actual coverage
   - Cons: Noisy, hard to distinguish real failures

**Consequences:**
- ‚úÖ Tests document intended behavior
- ‚úÖ Clear activation path (remove `.skip`)
- ‚úÖ Easy to see what's pending
- ‚ö†Ô∏è Skip count high initially (psychological effect)
- ‚ö†Ô∏è Must remember to activate as features ship

## AD-006: TypeScript Import Strategy

**Status:** Accepted

**Context:**
- Playwright tests run in Node.js environment
- TypeScript configured without `esModuleInterop`
- Default imports fail for Node.js built-ins

**Decision:**
Use namespace imports (`import * as fs from 'fs'`) for all Node.js built-in modules in test files.

**Alternatives Considered:**

1. **Enable esModuleInterop**
   - Pros: Allows default imports
   - Cons: May break existing code, affects entire project

2. **Require Syntax**
   - Pros: Always works in Node.js
   - Cons: Mixing CommonJS and ES modules, no type safety

3. **Mix: Default for Some, Namespace for Others**
   - Pros: "Natural" imports
   - Cons: Inconsistent, confusing for team

**Consequences:**
- ‚úÖ Consistent import style in tests
- ‚úÖ No TypeScript config changes
- ‚úÖ Works with current setup
- ‚ö†Ô∏è Verbose syntax (`fs.readFileSync` vs `readFileSync`)
- ‚ö†Ô∏è Different from src/ import style

## AD-007: Error Test Coverage Strategy

**Status:** Accepted

**Context:**
- Error cases often overlooked in manual testing
- Network errors, validation errors, auth errors all need testing
- Real errors hard to reproduce consistently

**Decision:**
Create dedicated `errors.spec.ts` with network mocking and edge case coverage.

**Alternatives Considered:**

1. **Mix Error Tests with Feature Tests**
   - Pros: Co-located with happy path
   - Cons: Files become large, hard to find error tests

2. **Skip Error Tests**
   - Pros: Focus on happy path first
   - Cons: Low error handling confidence, bugs in production

3. **Unit Test Errors Only**
   - Pros: Faster, more targeted
   - Cons: Doesn't test full stack error flow

**Consequences:**
- ‚úÖ Comprehensive error coverage
- ‚úÖ Easy to find all error scenarios
- ‚úÖ Tests actual user experience of errors
- ‚ö†Ô∏è Network mocking may not match production exactly
- ‚ö†Ô∏è Requires maintenance as APIs change

## AD-008: baseURL Hardcoding in Fixtures

**Status:** Accepted (Pragmatic)

**Context:**
- Need to construct API URLs in fixtures
- Playwright's baseURL is in config, not easily accessible in fixtures
- TypeScript errors when accessing private `_options` property

**Decision:**
Hardcode `baseURL = 'http://localhost:3000'` in fixtures with comment explaining it matches config.

**Alternatives Considered:**

1. **Pass baseURL to Fixtures**
   - Pros: DRY, type-safe
   - Cons: Fixtures become more complex, every call needs param

2. **Access via `page.context().browser()`**
   - Pros: Single source of truth
   - Cons: TypeScript errors, accessing private API

3. **Environment Variable**
   - Pros: Configurable
   - Cons: Another config to maintain, easy to forget

**Consequences:**
- ‚úÖ Simple, clear code
- ‚úÖ No TypeScript errors
- ‚úÖ Works immediately
- ‚ö†Ô∏è Duplicate config value (DRY violation)
- ‚ö†Ô∏è Must update in two places if port changes
- ‚ö†Ô∏è Doesn't work with custom baseURL

**Mitigation:**
Add comment: `// Use configured baseURL from playwright.config.ts`

## AD-009: Test Data Cleanup Strategy

**Status:** Deferred

**Context:**
- Test data accumulates in database
- Cleanup after each test is slow
- Cleanup on failure may not run

**Decision:**
Initial implementation: No cleanup between tests. Manual cleanup via DELETE endpoint.

**Future Decision Needed:**
Evaluate these approaches after initial implementation:

1. **Transaction Rollback**
   - Wrap each test in transaction, rollback
   - Requires Prisma transaction support in test context

2. **Database Reset**
   - Drop and recreate DB between test suites
   - Requires fast DB (SQLite for tests?)

3. **Cleanup in Global Teardown**
   - Delete all test data after all tests
   - Doesn't help with test isolation

**Consequences:**
- ‚úÖ Fast initial implementation
- ‚ö†Ô∏è Test data accumulates
- ‚ö†Ô∏è May cause test interdependencies
- üîÆ Future decision required based on actual issues

## Decision Review Schedule

These decisions should be reviewed after:
- ‚úÖ First full test run (validate performance gains)
- ‚úÖ First production deployment (validate security)
- üî≤ First month of usage (validate maintenance burden)
- üî≤ Team onboarding (validate developer experience)

### patch-validation/learnings.md
# PATCH Validation Learnings

## Changes Made

### 1. Created Validation Schemas
Created Zod validation schemas for all PATCH endpoints:

- **Campaign** (`src/lib/validations/campaign.ts`)
  - `updateCampaignSchema`: Partial update schema (excluding `objective` which cannot be changed)

- **Team** (`src/lib/validations/team.ts`)
  - `updateTeamSchema`: Team name and description validation
  - `updateTeamMemberSchema`: Member role, permissions, and action validation

- **A/B Test** (`src/lib/validations/abtest.ts`)
  - `updateABTestSchema`: Action (start/pause/complete) and variant metrics validation

- **Budget Alert** (`src/lib/validations/budgetAlert.ts`)
  - `createBudgetAlertSchema`: Threshold percent validation (1-100)
  - `updateBudgetAlertSchema`: Partial update for threshold and enabled status

- **Admin User** (`src/lib/validations/admin.ts`)
  - `updateUserSchema`: User name and global role validation

### 2. Updated PATCH Handlers
All PATCH endpoints now use Zod validation via `validateBody()` helper:

1. `/api/campaigns/[id]` - Campaign updates
2. `/api/teams/[id]` - Team details updates
3. `/api/teams/[id]/members/[memberId]` - Team member updates
4. `/api/ab-tests/[id]` - A/B test status and metrics updates
5. `/api/campaigns/[id]/budget-alert` - Budget alert settings updates
6. `/api/admin/users/[id]` - Admin user updates

### 3. Key Patterns

#### Using validateBody Helper
```typescript
const validation = await validateBody(request, updateSchema)
if (!validation.success) return validation.error

const { field1, field2 } = validation.data
```

#### Partial Schema Pattern
```typescript
export const updateSchema = createSchema.partial()
// or
export const updateSchema = z.object({
  field1: z.string().optional(),
  field2: z.number().optional(),
})
```

#### Validation Error Response Format
```json
{
  "error": "Validation failed",
  "details": [
    {
      "field": "fieldName",
      "message": "Error message"
    }
  ]
}
```

### 4. Benefits

1. **Type Safety**: All request bodies are validated at runtime and compile-time
2. **Consistent Error Handling**: Standardized validation error responses
3. **Better Documentation**: Schema serves as API documentation
4. **Reduced Boilerplate**: No manual validation logic in route handlers
5. **Easier Testing**: Schemas can be tested independently

### 5. Gotchas

- **TeamPermission Format**: Team permissions use `campaign:read` format, not `VIEW_CAMPAIGNS`
- **Partial Updates**: Use `.partial()` or make all fields `.optional()` for PATCH endpoints
- **Omit Fields**: Use `.omit()` to exclude fields that shouldn't be updated (e.g., `objective` in campaigns)
- **Default Values**: Use `.default()` for optional fields with fallback values (e.g., `thresholdPercent` defaults to 80)

### 6. Type Checking Verified

All changes pass TypeScript type checking:
```bash
npm run type-check
# ‚úì No errors
```